{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 감성 분석 : Sentiment Analysis(SA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 정의\n",
    "\n",
    "    sentiment ?\n",
    "    - attitudes, emotions, opinions (사실 x, 주관 o) \n",
    "    \n",
    "- 사용자의 감성과 관련된 텍스트 정보를 자동으로 추출하는 텍스트 마이닝(text mining) 기술의 한 영역으로, \n",
    "\n",
    "    문서를 작성한 사람이 어떠한 감성을 가지고 있는가를 판단하여 객관적이고 체계적으로 수치화하는 기술을 말한다\n",
    "\n",
    "\n",
    "### 2. 감성분석 사례\n",
    "- 제품 리뷰 긍정/부정?\n",
    "- 주식시장의 변동 예측\n",
    "- 선거 이후 대통령에 대한 태도 변화?(12년 미국 대선)\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 감성분석의 3가지 과제\n",
    "- 주관-객관 극성 판단\n",
    "- 긍정-부정 극성 판단\n",
    "- 긍정-부정 강도 판단\n",
    "\n",
    "    ; 이 작업을 위해 감정어 사전사용   \n",
    "    ( 감정어 사전 : sentiwordnet(영어), KOSAC(한글), Liwc ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 감성분석의 3단계 : 데이터 수집 - 주관성 탐지 - 극성 탐지\n",
    "\n",
    "1) 데이터 수집(Data Collection)\n",
    "\n",
    "2) 주관성 탐지 (Subjectivity Detection)\n",
    "     - 주관성이 없는 부분 제외 / 개인정보(이름, 성별) 제외\n",
    "\n",
    "3) 극성 탐지(분석) (Polarity Detection) \n",
    "    - 데이터가 긍정 or 부정 or 중립인지 판단 후, 통계적 기법 적용\n",
    "    - 각 단어의 '빈도' or 긍,부정 같은 '속성'에 따라 가중치 부여한 뒤, 전체 텍스트의 극성을 분석\n",
    "    - '문서' 단위의 분석 / '속성' 단위의 분석 : 단순히 긍정(부정) 단어의 갯수를 세는 것은 텍스트 전체의 의미를 잘못 해석할 가능성O\n",
    "        ->문서 단위 분석은 오류 확률큼/ 속성 단위 분석 사용 한줄한줄씩 읽어나가기\n",
    "    - '담화'분석 : 여러 문장 사이의 연관성·문맥 고려해 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. SA에 사용되는 언어 모형 및 알고리즘\n",
    "\n",
    "#### 1. 언어 모형\n",
    "\n",
    "- 유니그램(Unigram) \n",
    "    - 컴퓨터가 사용하는 대표적 언어 모형\n",
    "    - '좋다','나쁘다'같이 하나의 단어를 다름\n",
    "    - 장점 : 통계적으로 정확한 모델을 제공 / 직관적인 해석 가능 / 비정형 데이터를 가장 간단하게 수치화\n",
    "    - 단점 : 단어의 순서와 같은 문법사항 고려하지 않음 \n",
    "    ( 좋지 않다 : 의미가 반대가 됨 // 매우 좋다 : 감성의 강도 셈 -> 해석 ㄴ)\n",
    "    \n",
    "    \n",
    "- 바이그램 (Bigram)\n",
    "    - 부정어나 강조 부사와 같이 두 단어 인식\n",
    "\n",
    "\n",
    "- N-gram : n개의 연속적 단어의 순서와 상관관계 파악가능\n",
    "\n",
    "#### 2. 알고리즘\n",
    "\n",
    "- 나이브 베이즈 \n",
    "    - 기본적 분류 알고리즘\n",
    "    - 텍스트가 긍/부정에 포함될 확률을 구하는 방법\n",
    "    - 텍스트를 순서가 없는 단순한 단어 집합으로 가정( BoW : bag of words )\n",
    "    - 단순 문서 카테고리 분류에서 80~90% 정확\n",
    "    \n",
    "    \n",
    "- 서포트 벡터 머신\n",
    "    - 단어의 문법적인 연관성 정확 판별\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 한계점\n",
    "- 영어와 비교, 한국어 감성 분석기술의 어려움이 큼\n",
    "( 어순의 자유로움, 주어·명사의 생략으로 모호)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EX01. 나이브베이즈 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk : natural language toolkit \n",
    "# 컴퓨터가 자연어 처리를하는데 사용하는 패키지\n",
    "# nltk 다운 : https://pypi.python.org/pypi/nltk#downloads\n",
    "import nltk\n",
    "from nltk.classify import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     C:\\Users\\Chankoo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\sentiwordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('sentiwordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Chankoo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3개의 클래스 정의\n",
    "\n",
    "positive_vocab = [ 'awesome', 'outstanding', 'fantastic', 'terrific', 'good', 'nice', 'great', ':)' ]\n",
    "negative_vocab = ['bad', 'terrible','useless', 'hate', ':(' ]\n",
    "neutral_vocab = [ 'home','movie','the','sound','was','is','actors','did','know','words','not']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW 정의\n",
    "\n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    "\n",
    "positive_features = [(word_feats(pos), 'pos') for pos in positive_vocab]\n",
    "negative_features = [(word_feats(neg), 'neg') for neg in negative_vocab]\n",
    "neutral_features = [(word_feats(neu), 'neu') for neu in neutral_vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'a': True, 'e': True, 'm': True, 'o': True, 's': True, 'w': True}, 'pos'),\n",
       " ({'a': True,\n",
       "   'd': True,\n",
       "   'g': True,\n",
       "   'i': True,\n",
       "   'n': True,\n",
       "   'o': True,\n",
       "   's': True,\n",
       "   't': True,\n",
       "   'u': True},\n",
       "  'pos'),\n",
       " ({'a': True,\n",
       "   'c': True,\n",
       "   'f': True,\n",
       "   'i': True,\n",
       "   'n': True,\n",
       "   's': True,\n",
       "   't': True},\n",
       "  'pos'),\n",
       " ({'c': True, 'e': True, 'f': True, 'i': True, 'r': True, 't': True}, 'pos'),\n",
       " ({'d': True, 'g': True, 'o': True}, 'pos'),\n",
       " ({'c': True, 'e': True, 'i': True, 'n': True}, 'pos'),\n",
       " ({'a': True, 'e': True, 'g': True, 'r': True, 't': True}, 'pos'),\n",
       " ({')': True, ':': True}, 'pos')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나이브베이즈 분류기로 training\n",
    "\n",
    "train_set = negative_features + positive_features + neutral_features\n",
    "classifier = NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 0.4\n",
      "Negative: 0.2\n",
      "Neutral: 0.4\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "\n",
    "neg = 0\n",
    "pos = 0\n",
    "neu = 0\n",
    "sentence = \"Awesome movie, I liked it\"\n",
    "sentence = sentence.lower()\n",
    "words = sentence.split(' ')\n",
    "\n",
    "for word in words:\n",
    "    classResult = classifier.classify(word_feats(word))\n",
    "    if classResult == 'neg':\n",
    "        neg = neg + 1\n",
    "    if classResult == 'pos':\n",
    "        pos = pos + 1\n",
    "    if classResult == 'neu':\n",
    "        neu = neu + 1\n",
    "\n",
    "print('Positive: ' + str(float(pos)/len(words)))\n",
    "print('Negative: ' + str(float(neg)/len(words)))\n",
    "print('Neutral: ' + str(float(neu)/len(words)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EX02. Sentiwordnet이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiwordnet 불러오기\n",
    "\n",
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SentiSynset('hate.n.01'), SentiSynset('hate.v.01')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(swn.senti_synsets('hate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'hate'의 긍정 스코어\n",
    "list(swn.senti_synsets('hate','v'))[0].pos_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'hate'의 부정 스코어\n",
    "list(swn.senti_synsets('hate','v'))[0].neg_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단어마다 여러 유의어가 존재하는 경우 : 특정 단어의 모든 유의어의 긍/부정 스코어를 평균해서 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SentiSynset('tire.n.01'),\n",
       " SentiSynset('tire.v.01'),\n",
       " SentiSynset('tire.v.02'),\n",
       " SentiSynset('run_down.v.06'),\n",
       " SentiSynset('bore.v.01')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(swn.senti_synsets('tire'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'tire'의 동사 유의어 점수 평균 (방법1)\n",
    "\n",
    "def word_sentiment_calculator(word,tag):\n",
    "    pos_score=0\n",
    "    neg_score=0\n",
    "    \n",
    "    if 'NN' in tag and len(list(swn.senti_synsets(word,'n')))>0:\n",
    "        syn_set = list(swn.senti_synsets(word,'n'))\n",
    "    elif 'VB' in tag and len(list(swn.senti_synsets(word,'v')))>0:\n",
    "        syn_set = list(swn.senti_synsets(word,'v'))\n",
    "    elif 'JJ' in tag and len(list(swn.senti_synsets(word,'a')))>0:\n",
    "        syn_set = list(swn.senti_synsets(word,'a'))\n",
    "    elif 'RB' in tag and len(list(swn.senti_synsets(word,'r')))>0:\n",
    "        syn_set = list(swn.senti_synsets(word,'r'))\n",
    "    else:\n",
    "        return (0,0)\n",
    "    \n",
    "    for syn in syn_set:\n",
    "        pos_score += syn.pos_score()\n",
    "        neg_score += syn.neg_score()\n",
    "        \n",
    "    return (pos_score/len(syn_set),neg_score/len(syn_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.09375, 0.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_sentiment_calculator('tire','VB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SentiSynset('tire.v.01'),\n",
       " SentiSynset('tire.v.02'),\n",
       " SentiSynset('run_down.v.06'),\n",
       " SentiSynset('bore.v.01')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'tire'의 동사 유의어 점수 평균 (방법2)\n",
    "list(swn.senti_synsets('tire','v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(swn.senti_synsets('tire','v'))[0].pos_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(swn.senti_synsets('tire','v'))[1].pos_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(swn.senti_synsets('tire','v'))[2].pos_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(swn.senti_synsets('tire','v'))[3].pos_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EX03-1. 영화 리뷰(Sentiwordnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://ai.stanford.edu/~amaas/data/sentiment/ \n",
    "# 샘플 데이터 다운 : 영화사이트 리뷰 5만개를 수집해 긍/부정 분류로 나눈 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "\n",
    "# os 패키지: operating system\n",
    "# 운영체제에서 쓰는 여러 기능들을 python에서 쓸수 있게 해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')\n",
    "# nltk.download('popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 긍정/부정 리뷰 10개씩 불러오기\n",
    "\n",
    "pos_files = os.listdir('aclImdb_v1.tar(sample)/test/pos')[:10]\n",
    "neg_files = os.listdir('aclImdb_v1.tar(sample)/test/neg')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 긍정, 부정 분류의 accuracy 살펴보자\n",
    "\n",
    "actual = [1]*10 + [0]*10 # 긍정(1), 부정(0)을 순서대로 불러왔기 때문에\n",
    "predicted = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장의 긍/부정 지수\n",
    "\n",
    "def sentence_sentiment_calculator(pos_tags): \n",
    "    pos_score=0\n",
    "    neg_score=0\n",
    "    s_tk=nltk.word_tokenize(pos_tags) # word_tokenize() :어절별로 나누기\n",
    "    pos_tags=nltk.pos_tag(s_tk) # pos_tag() : 형태소 출력\n",
    "    \n",
    "    for word,tag in pos_tags:\n",
    "        pos_score += word_sentiment_calculator(word,tag)[0] # pos 평균값\n",
    "        neg_score += word_sentiment_calculator(word,tag)[1] # neg 평균값\n",
    "        \n",
    "    return(pos_score,neg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5232905982905983, 0.7358974358974358)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 확인\n",
    "\n",
    "sentence_sentiment_calculator(\"i am very tired, i want to go home\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### actual vs predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_10.txt\n",
      "100_10.txt\n",
      "101_9.txt\n",
      "102_8.txt\n",
      "103_10.txt\n",
      "104_10.txt\n",
      "105_8.txt\n",
      "106_9.txt\n",
      "107_10.txt\n",
      "108_10.txt\n"
     ]
    }
   ],
   "source": [
    "# 긍정 스코어를 대/소 비교(pos_files)\n",
    "# 긍정 doc 10개\n",
    "for file in pos_files:\n",
    "    print(file)\n",
    "    with open('aclImdb_v1.tar(sample)/test/pos/{}'.format(file),'r',encoding='utf-8') as f:\n",
    "        scores = sentence_sentiment_calculator(f.read())\n",
    "        \n",
    "        if scores[0] >= scores[1]:\n",
    "            predicted.append(1)   # 긍정 수치가 높으면 1반환\n",
    "        else:\n",
    "            predicted.append(0)  # 부정 수치가 높은면 0 반환\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 부정 스코어를 대/소 비교(neg_files)\n",
    "# 부정 doc 10개\n",
    "for file in neg_files:\n",
    "    with open('aclImdb_v1.tar(sample)/test/neg/{}'.format(file),'r',encoding='utf-8') as f:\n",
    "        scores = sentence_sentiment_calculator(f.read())\n",
    "        \n",
    "        if scores[0] >= scores[1]:\n",
    "            predicted.append(1) # 긍정 수치가 높으면 1반환\n",
    "        else:\n",
    "            predicted.append(0)  # 부정 수치가 높은면 0 반환\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct/incorrect 갯수\n",
    "\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "\n",
    "for i in range(20):\n",
    "    if actual[i] == predicted[i]:\n",
    "        correct +=1\n",
    "    else:\n",
    "        incorrect +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(actual) \n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct instance:  13\n",
      "Number of incorrect instance:  7\n"
     ]
    }
   ],
   "source": [
    "print('Number of correct instance: ',correct)\n",
    "print('Number of incorrect instance: ',incorrect)\n",
    "\n",
    "# 13/20(65%)의 확률의 성능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EX03-2. 영화리뷰(Naive Bayes Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopWords=set(stopwords.words('english'))\n",
    "\n",
    "# stopword(불용어) : 인터넷 검색 시 검색 용어로 사용하지 않는 단어, 관사, 조사 등등 의미 없는 단어\n",
    "# nltk의 불용어 특징: 각 글자가 소문자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'m', 'isn', 'having', 'other', 'just', 'can', 'didn', 'hadn', \"haven't\", 'most', 'until', 'such', 'again', \"hadn't\", 'further', 'off', 'you', 'o', 'at', \"shan't\", \"mightn't\", 'have', 's', 'from', 're', 'few', \"you've\", 'because', 'been', 'but', \"should've\", 'aren', 'with', 'mustn', \"wouldn't\", 'and', 'don', 'which', 'an', 'the', 'a', 'here', 'then', \"she's\", 'its', 'how', 'same', 'i', 'they', \"it's\", 'more', 'll', 'will', 'through', 'where', 'had', 'hers', 'is', 'some', 'needn', 'too', 'them', 'during', 'did', 'was', 'were', 'any', \"won't\", \"doesn't\", 'he', 'ourselves', 'or', 'itself', 'himself', 'doesn', 'me', 'd', 'as', 'than', 'y', 'be', \"didn't\", 'shan', 'she', 'that', \"mustn't\", 'what', 'out', 'whom', 'under', 'only', 'yourselves', 'do', 'haven', 'it', 'why', 'both', 'of', 'for', 'ain', 'hasn', \"couldn't\", 'before', 'his', 'after', 't', 'theirs', 'ma', 'to', 'her', 'your', \"don't\", 'my', 'yourself', 'shouldn', 'myself', 'very', 'are', 'we', 'over', 'in', \"wasn't\", 'being', \"you're\", \"you'd\", 'am', 'above', \"aren't\", 'does', \"you'll\", 'themselves', 'while', 'our', 'if', 'doing', 'own', 'their', 'there', 'couldn', 'wasn', 'all', 'weren', 'once', 've', 'won', \"shouldn't\", 'up', 'by', 'those', 'yours', \"isn't\", \"that'll\", 'below', 'about', 'now', \"hasn't\", 'on', 'should', 'when', \"needn't\", 'this', 'no', 'into', 'who', 'nor', \"weren't\", 'mightn', 'herself', 'these', 'each', 'wouldn', 'so', 'him', 'against', 'between', 'has', 'down', 'not', 'ours'}\n"
     ]
    }
   ],
   "source": [
    "print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47288\n"
     ]
    }
   ],
   "source": [
    "words = [] \n",
    "\n",
    "# 긍정 학습 리뷰를 word 리스트로\n",
    "\n",
    "files=os.listdir('aclImdb_v1.tar(sample)/test/pos')\n",
    "\n",
    "for file in files:\n",
    "    with open('aclImdb_v1.tar(sample)/test/pos/{}'.format(file),'r',encoding = 'utf-8') as f:\n",
    "        review = nltk.word_tokenize(f.read()) # 어절별로 나누기\n",
    "        \n",
    "        for token in review:\n",
    "            if token not in stopWords:\n",
    "                words.append(token)  # 불용어 제거\n",
    "                \n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91333\n"
     ]
    }
   ],
   "source": [
    "# 같은 방식으로 부정 학습 데이터를 word 리스트로\n",
    "\n",
    "files=os.listdir('aclImdb_v1.tar(sample)/test/neg')\n",
    "\n",
    "for file in files:\n",
    "    with open('aclImdb_v1.tar(sample)/test/neg/{}'.format(file),'r',encoding = 'utf-8') as f:\n",
    "        review = nltk.word_tokenize(f.read())\n",
    "        for token in review:\n",
    "            if token not in stopWords:\n",
    "                words.append(token)\n",
    "                \n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words의 상위 3000개만 사용\n",
    "\n",
    "words=nltk.FreqDist(words) # FreqDist() : 빈도수 분석\n",
    "word_features=list(words.keys())[:3000] #상위 3000개 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffI', 'went', 'saw', 'movie', 'last', 'night', 'coaxed', 'friends', 'mine', '.', 'I', \"'ll\", 'admit', 'reluctant', 'see', 'knew', 'Ashton', 'Kutcher', 'able', 'comedy', 'wrong', 'played', 'character', 'Jake', 'Fischer', 'well', ',', 'Kevin', 'Costner', 'Ben', 'Randall', 'professionalism', 'The', 'sign', 'good', 'toy', 'emotions', 'This', 'one', 'exactly', 'entire', 'theater', '(', 'sold', ')', 'overcome', 'laughter', 'first', 'half', 'moved', 'tears', 'second', 'While', 'exiting', 'many', 'women', 'full', 'grown', 'men', 'trying', 'desperately', 'let', 'anyone', 'crying', 'great', 'suggest', 'go', 'judge', 'finest', 'short', \"'ve\", 'ever', 'seen', 'Some', 'commentators', 'might', 'lengthened', 'due', 'density', 'insight', 'offers', 'There', \"'s\", 'irony', 'comment', 'little', 'merit', 'acting', 'Noonan', 'carries', 'thankless', 'perfectly', 'preferred', 'narrator', 'less', '``', 'recognizable', \"''\", 'gravitas', 'lent']\n"
     ]
    }
   ],
   "source": [
    "print(word_features[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features를 보여주는 함수 생성\n",
    "\n",
    "def find_features(doc):\n",
    "    words = set(doc)\n",
    "    features = {}\n",
    "    \n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1번째 리뷰데이터 feature 생성 : \n",
    "#Once again Mr. Costner has dragged out a movie for far longer than necessary~~\n",
    "\n",
    "with open('aclImdb_v1.tar(sample)/test/neg/{}'.format(files[0]),'r',encoding='utf-8') as f:\n",
    "    review = nltk.word_tokenize(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_features(review)['saw'] #saw 는 doc에 불포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_features(review)['movie'] # movie는 포함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "긍/부정 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 250개의 리뷰 데이터에 대한 feature set 생성\n",
    "feature_sets =[]\n",
    "\n",
    "\n",
    "# training(pos)\n",
    "files = os.listdir('aclImdb_v1.tar(sample)/train/pos')[:250]\n",
    "for file in files:\n",
    "    with open('aclImdb_v1.tar(sample)/train/pos/{}'.format(file),'r',encoding='utf-8') as f:\n",
    "            review = nltk.word_tokenize(f.read())\n",
    "            feature_sets.append((find_features(review),'pos'))\n",
    "\n",
    "# training(neg)         \n",
    "files = os.listdir('aclImdb_v1.tar(sample)/train/neg')[:250]\n",
    "for file in files:\n",
    "    with open('aclImdb_v1.tar(sample)/train/neg/{}'.format(file),'r',encoding='utf-8') as f:\n",
    "            review = nltk.word_tokenize(f.read())\n",
    "            feature_sets.append((find_features(review),'neg'))\n",
    "            \n",
    "          \n",
    "\n",
    "        #########################################\n",
    "\n",
    "        \n",
    "# test(pos)\n",
    "files = os.listdir('aclImdb_v1.tar(sample)/test/pos')[:250]\n",
    "for file in files:\n",
    "    with open('aclImdb_v1.tar(sample)/test/pos/{}'.format(file),'r',encoding='utf-8') as f:\n",
    "            review = nltk.word_tokenize(f.read())\n",
    "            feature_sets.append((find_features(review),'pos'))\n",
    "            \n",
    "            \n",
    "# test(neg)\n",
    "files = os.listdir('aclImdb_v1.tar(sample)/test/neg')[:250]\n",
    "for file in files:\n",
    "    with open('aclImdb_v1.tar(sample)/test/neg/{}'.format(file),'r',encoding='utf-8') as f:\n",
    "            review = nltk.word_tokenize(f.read())\n",
    "            feature_sets.append((find_features(review),'neg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = feature_sets[:500]\n",
    "test_set = feature_sets[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = nltk.classify.accuracy(clf, test_set)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Naive Bayes classification model:  78.60000000000001\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the Naive Bayes classification model: ', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('worst', True),\n",
       " ('Unfortunately', True),\n",
       " ('single', True),\n",
       " ('loved', True),\n",
       " ('brilliant', True),\n",
       " ('elements', True),\n",
       " ('amount', True),\n",
       " ('result', True),\n",
       " ('Instead', True),\n",
       " ('beauty', True),\n",
       " ('emotions', True),\n",
       " ('masterpiece', True),\n",
       " ('fantastic', True),\n",
       " ('George', True),\n",
       " ('William', True),\n",
       " ('terrible', True),\n",
       " ('sees', True),\n",
       " ('superb', True),\n",
       " ('Miss', True),\n",
       " ('begin', True)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.most_informative_features()[:20] #most_informative한 단어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   worst = True              neg : pos    =     29.0 : 1.0\n",
      "           Unfortunately = True              neg : pos    =      9.7 : 1.0\n",
      "                  single = True              neg : pos    =      7.7 : 1.0\n",
      "                   loved = True              pos : neg    =      7.3 : 1.0\n",
      "               brilliant = True              pos : neg    =      7.0 : 1.0\n",
      "                elements = True              pos : neg    =      6.6 : 1.0\n",
      "                  amount = True              neg : pos    =      6.3 : 1.0\n",
      "                  result = True              neg : pos    =      6.3 : 1.0\n",
      "                 Instead = True              neg : pos    =      6.3 : 1.0\n",
      "                  beauty = True              pos : neg    =      6.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "clf.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
